{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ce12c6-a953-4d45-abf1-93800620776c",
   "metadata": {},
   "source": [
    "### Now we run our model on the empty dataset to compare precision compared to actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70145336-47ac-48ef-b0d2-bb823233881b",
   "metadata": {},
   "source": [
    "#### Now we load our fine tuned model first before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a61b1d6-bb6a-4e37-8c40-a0b71dad32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Setup\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# model_path = \"/content/drive/MyDrive/t5-finetuned\"\n",
    "model_path = \"./t5_multitask_finetuned\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict(input_text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    outputs = model.generate(inputs, max_length=64)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aecfad-c325-4505-8170-ffffdb4105e2",
   "metadata": {},
   "source": [
    "### Now we try to predict something on a single manual string before inputting as a whole file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7241b2ac-76fa-429e-8ec7-1bed0cf39fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Title: Dreamweaving\n"
     ]
    }
   ],
   "source": [
    "text = \"title: In the mystical realm of Somnium, where dreams take on lives of their own, a young apprentice named Lyra discovers she possesses the rare gift of Dreamweaving. With the ability to shape and control the fabric of the subconscious, Lyra is tasked with unraveling the mystery behind a series of dark and foreboding dreams that threaten to consume the dreams of Somnium's inhabitants\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_length=16)\n",
    "print(\"Generated Title:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a28e27-7c34-4484-883c-b015ea70d3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre: ['fantasy'\n"
     ]
    }
   ],
   "source": [
    "text = \"genre: In the mystical realm of Somnium, where dreams take on lives of their own, a young apprentice named Lyra discovers she possesses the rare gift of Dreamweaving. With the ability to shape and control the fabric of the subconscious, Lyra is tasked with unraveling the mystery behind a series of dark and foreboding dreams that threaten to consume the dreams of Somnium's inhabitants\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs)\n",
    "print(\"Predicted Genre:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f3e109-eeea-4f49-b19c-0136fa677d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Rating: 4.13\n"
     ]
    }
   ],
   "source": [
    "text = \"rating: In the mystical realm of Somnium, where dreams take on lives of their own, a young apprentice named Lyra discovers she possesses the rare gift of Dreamweaving. With the ability to shape and control the fabric of the subconscious, Lyra is tasked with unraveling the mystery behind a series of dark and foreboding dreams that threaten to consume the dreams of Somnium's inhabitants\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs)\n",
    "print(\"Predicted Rating:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96847455-5ea8-439b-853e-1f73c9918c47",
   "metadata": {},
   "source": [
    "#### Now we try to predict everything on batch using csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b073323-4778-4446-8083-86e4e63e2fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94008 [00:00<?, ?it/s]/tmp/ipykernel_30/1601844826.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.04' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'rating'] = rating_pred\n",
      "/tmp/ipykernel_30/1601844826.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['young adult'' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'genre'] = genre_pred\n",
      "  0%|          | 138/94008 [01:11<14:38:42,  1.78it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the CSV file where 'genre' and 'rating' are empty\n",
    "df = pd.read_csv('./archive/cleaned/merged_all_for_prediction.csv')\n",
    "\n",
    "# Ensure 'predictedTitle' column exists as the last column\n",
    "df['predictedTitle'] = \"\"\n",
    "\n",
    "# Batch prediction for each row\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # Prepare input for each task\n",
    "    base_text = f\"{row['title']} {row['description']}\"\n",
    "    \n",
    "    # Predict rating\n",
    "    rating_input = f\"rating: {base_text}\"\n",
    "    rating_pred = predict(rating_input)\n",
    "    df.at[idx, 'rating'] = rating_pred\n",
    "\n",
    "    # Predict genre\n",
    "    genre_input = f\"genre: {base_text}\"\n",
    "    genre_pred = predict(genre_input)\n",
    "    df.at[idx, 'genre'] = genre_pred\n",
    "\n",
    "    # Predict title\n",
    "    title_input = f\"title: {base_text}\"\n",
    "    title_pred = predict(title_input)\n",
    "    df.at[idx, 'predictedTitle'] = title_pred\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "df.to_csv('./archive/cleaned/merged_all_with_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
